<h1 align="center">ğŸ“Š Credit Score Modelling ğŸ”</h1>
<p align="center">
  <img src="https://akm-img-a-in.tosshub.com/businesstoday/images/story/202409/66ed0877cefd4-how-to-improve-your-credit-score-with-a-credit-card-203030461-16x9.jpg?size=948:533" alt="Credit Scoring"/>
</p>
<p align="center">
  A robust and production-ready pipeline for Credit Risk Modeling using statistical binning, scorecard development, MLflow tracking, DVC versioning, and Streamlit visualization.
</p>

---

## ğŸ“š Table of Contents

- [ğŸ“Œ Project Overview](#-project-overview)
- [âœ¨ Key Features](#-key-features)
- [ğŸ§  System Architecture Overview](#-system-architecture-overview)
- [ğŸ“‚ Project Directory Structure](#-project-directory-structure)
- [ğŸ’» Local Usage Instructions](#-local-usage-instructions)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ”„ DVC Pipeline Stages](#-dvc-pipeline-stages)
- [ğŸ“ˆ MLflow Tracking](#-mlflow-tracking)
- [ğŸ§ª Evaluation Metrics](#-evaluation-metrics)
- [ğŸ—ƒï¸ Dataset Source](#ï¸-dataset-source)
- [ğŸ§ª Research Notebooks](#-research-notebooks)
- [ğŸ“¤ Future Enhancements](#-future-enhancements)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“œ License](#-license)
- [ğŸ“© Contact](#-contact)

---

## ğŸ“Œ Project Overview

**Credit Score Modelling** is a complete, modularized pipeline that automates the process of building, validating, and deploying credit risk models. It follows best practices of MLOps using tools like **DVC**, **MLflow**, **FastAPI**, and **Streamlit**, and applies **optimal binning** and **logistic regression** to build scorecards aligned with traditional credit risk modeling methodologies.

### ğŸ¯ Project Goal
To develop a **credit risk scorecard** using statistical modeling principles that can:
- Evaluate loan default risk
- Visualize binning and scorecard metrics
- Be version-controlled and production-deployable
- Enable user interaction through a modern frontend

---

## âœ¨ Key Features

âœ… **Modular ML pipeline** with DVC tracking and reproducibility  
âœ… **MLflow logging** (supports both local and remote servers like DagsHub)  
âœ… **Optimal binning & scaling** using `scorecardpy` and `optbinning`  
âœ… **Scorecard training** with pdo/odds scaling  
âœ… **Streamlit dashboard** for loan risk prediction  
âœ… **FastAPI backend** for real-time serving  
âœ… **Docker-ready**, CI/CD friendly architecture  

---

## ğŸ§  System Architecture Overview

```mermaid
flowchart TD
    A["Raw Data - Kaggle"] --> B["Data Ingestion"]
    B --> C["Data Validation"]
    C --> D["Binning & Transformation"]
    D --> E["Data Versioning - DVC / Splitting - train/test/oot"]
    E --> F["ML Model Training - Scorecard"]
    F --> G["Model Evaluation"]
    G --> H["MLflow Logging"]
    H --> I["Prediction API - FastAPI"]
    I --> J["User Interface - Streamlit"]
```

---

## ğŸ“‚ Project Directory Structure

```bash
credit-score-modelling/
â”œâ”€â”€ app.py                        # Streamlit frontend
â”œâ”€â”€ main.py                       # FastAPI backend
â”œâ”€â”€ config/                       # YAML configs and schema
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ schema.yaml
â”œâ”€â”€ data/                         # Raw data files (Kaggle)
â”œâ”€â”€ artifacts/                    # DVC-tracked outputs (data, model, metrics)
â”œâ”€â”€ notebooks/                    # EDA and experimentation
â”œâ”€â”€ saved_models/                 # Final scorecard and pushed models
â”œâ”€â”€ src/                          # Modular source code
â”‚   â”œâ”€â”€ components/               # Core ML pipeline components
â”‚   â”œâ”€â”€ config/                   # Load and manage configuration
â”‚   â”œâ”€â”€ entity/                   # Entity/data classes for config & outputs
â”‚   â”œâ”€â”€ exception/                # Custom exceptions
â”‚   â”œâ”€â”€ logger/                   # Logging setup
â”‚   â”œâ”€â”€ pipeline/                 # Pipeline orchestration
â”‚   â”œâ”€â”€ schema/                   # Input/output schema
â”‚   â””â”€â”€ utils/                    # Utilities (MLflow, metrics, file ops)
â”œâ”€â”€ requirements.txt              # All required Python packages
â”œâ”€â”€ params.yaml                   # ML model parameters
â”œâ”€â”€ dvc.yaml                      # DVC pipeline stages
â”œâ”€â”€ Dockerfile                    # Docker setup
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

| Folder/File   | Purpose                                                       |
| ------------- | ------------------------------------------------------------- |
| `components/` | Core steps in your ML pipeline                                |
| `entity/`     | Data classes to pass structured outputs across pipeline steps |
| `pipeline/`   | Orchestration of training/prediction steps                    |
| `config/`     | All external config, schema, and loaders                      |
| `exception/`  | Custom exception for consistent error tracking                |
| `logger/`     | Logging config and setup                                      |
| `utils/`      | Helper utilities like file ops, time utils, data I/O          |
| `artifacts/`  | Output folders for every stage to trace and reuse outputs     |
| `main.py`     | Entry point (FastAPI backend)                                 |
| `app.py`      | Streamlit (frontend), for user loan application input         |


## ğŸ’» Local Usage Instructions

### 1. **Clone the Repository**
```bash
git clone https://github.com/kousik23naskar/credit-score-modelling.git
cd credit-score-modelling
```
### 2. **Set Up Virtual Environment with uv**
```bash
uv venv --python 3.12
source .venv/bin/activate
```
### 3. **Initialize Project with UV**
```bash
uv init
```
### 4. **Install Dependencies**
```bash
uv add -r requirements.txt
```
### 5. **Run pipeline with DVC Tracking**
```bash
dvc init
dvc repro
```
### 6. **Start Backend API (FastAPI)**
```bash
uvicorn main:app --reload
```
### 7. **Launch Streamlit Frontend**
```bash
streamlit run app.py
```

Now open your browser and go to the URL (usually `http://localhost:8501`).

## ğŸ› ï¸ Tech Stack

- ğŸ **Python 3.12**

- ğŸ“¦ **uv (Dependency & venv manager)**

- ğŸ“Š **optbinning, scorecardpy**

- ğŸ“‹ **pandas, scikit-learn**

- ğŸ” **DVC for pipeline tracking**

- ğŸ§ª **MLflow for experiment logging**

- ğŸŒ **FastAPI as backend**

- ğŸ–¼ï¸ **Streamlit for frontend**

- ğŸ³ **Docker for containerization**



## ğŸ”„ DVC Pipeline Stages
```yaml
stages:
  data_ingestion: 
    cmd: PYTHONPATH=. python src/pipeline/data_ingestion_pipeline.py
  data_validation: 
    cmd: PYTHONPATH=. python src/pipeline/data_validation_pipeline.py
  data_transformation: 
    cmd: PYTHONPATH=. python src/pipeline/data_transformation_pipeline.py
  model_trainer: 
    cmd: PYTHONPATH=. python src/pipeline/model_trainer_pipeline.py
  model_evaluation: 
    cmd: PYTHONPATH=. python src/pipeline/model_evaluation_pipeline.py
  model_pusher: 
    cmd: PYTHONPATH=. python src/pipeline/model_pusher_pipeline.py
```

---

## ğŸ“ˆ MLflow Tracking
Supports both:

- âœ… Local MLflow tracking (mlruns folder), cmd: `mlflow ui`
- âœ… Remote tracking server (e.g., DagsHub: `mlflow.set_tracking_uri("https://dagshub.com/username/repo.mlflow")`)

Set your preferred tracking URI in `config.yaml`.

## ğŸ§ª Evaluation Metrics
All  metrices are logged in MLflow

- âœ… AUC/GINI/KS: Your model ranks predictions very well â€” strong ability to distinguish defaults from non-defaults.

- âœ… PR-AUC: Reflects good precision-recall tradeoff, especially important for imbalanced datasets like credit risk.

- âœ… Brier Score: Low value confirms your predicted probabilities are well calibrated, especially when paired with your improved calibration curve. **Calibration Monitor â†’** recalibrate if Brier â‰¥ 0.20

- âœ… PSI: To detect shifts in feature distributions, monitor Population Stability Index (PSI) between training and production data. A PSI < 0.1 indicates stable distributions, while > 0.2 suggests significant shifts.

## ğŸ—ƒï¸ Dataset Source
This project uses the Credit Risk Dataset from [Kaggle](https://www.kaggle.com/datasets/laotse/credit-risk-dataset), featuring loan and applicant attributes for binary default classification.


## ğŸ§ª Research Notebooks
- `EDA.ipynb`: Exploratory Data Analysis
- `modelling_with_optbinning.ipynb`: Binning, WOE, IV, Model development and experimentation

## ğŸ“¤ Future Enhancements

- ğŸ”® AutoML integration
- ğŸ“Š Dashboarding with more charts and explanations

## ğŸ¤ Contributing
We welcome contributions!
Please open an issue or submit a pull request for improvements.

## ğŸ“œ License
This project is licensed under the [MIT License](LICENSE).

## ğŸ“© Contact

- **Author:** Dr. Kousik Naskar

- **Email:** kousik23naskar@gmail.com

- **LinkedIn:** [Kousik Naskar](https://www.linkedin.com/in/dr-kousik-naskar/)

Thanks for exploring the Credit Score Modelling project! We hope it serves as a valuable resource for your credit risk modeling needs. If you have any questions or suggestions, feel free to reach out.